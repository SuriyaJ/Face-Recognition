{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criminal prediction using Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now-a-days most people in this modern age has atleast one vehicle in their homes. The owners are in fear of having their vehicles being stolen from outside of their home.In image analysis,Face recognition is one of the important and successful method.The concept of Face recognition can be applied to vehicle security.This can be done by recognizing the facial features of the authorized person to unlock the engines.In case of any theft, the system will not let engines start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MongoDB is a noSQL database which used to store huge amount Data with key value pairs\n",
    "import dlib\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import pymongo\n",
    "import datetime\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"mydatabase\"]\n",
    "mycol = mydb[\"attendance\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Note:\n",
    "\n",
    "The images of the authenticated people who can access the vehicle are stored in the folder called hs. The below code collects the images with their image names from the hs folder for example owner jack image with name jack.jpg. Images are stored in images list and their Labels are stored in classnames list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of oriented gradiants(HOG) classifier:- \n",
    "\n",
    "They find the facial landmarks of the tilted images and make the image look straight with the use of D-lib library at the backend . After this process they send this image to the neural network that gives us the encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['harish.jpg', 'himg.jpg', 'suriya.jpg']\n",
      "['harish', 'himg', 'suriya']\n",
      "encodings complete\n",
      "[0.58169043 0.89700895 0.47714234]\n",
      "suriya\n",
      "[0.59591002 0.92423643 0.50875631]\n",
      "suriya\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images=[]\n",
    "classnames=[]\n",
    "path='hs/'\n",
    "mylist=os.listdir(path)\n",
    "print(mylist)\n",
    "for cl in mylist:\n",
    "    curimage=cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curimage)                    \n",
    "    classnames.append(os.path.splitext(cl)[0])                   \n",
    "print(classnames) \n",
    "def findencodings(images):\n",
    "    encodings=[]\n",
    "    for img in images:\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        faceloc=face_recognition.face_locations(img)[0]\n",
    "        encodehar=face_recognition.face_encodings(img)[0]\n",
    "        encodings.append(encodehar)\n",
    "    return encodings\n",
    "encodelistknown=findencodings(images)\n",
    "print('encodings complete')\n",
    "cap=cv2.VideoCapture(0)\n",
    "flag=True\n",
    "c=0\n",
    "while(flag==True):\n",
    "    success,img=cap.read()\n",
    "    #img=cv2.resize(img,(0,0),None,0.25,0.25)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    facelocq=face_recognition.face_locations(img)\n",
    "    encodeharq=face_recognition.face_encodings(img,facelocq)\n",
    "    for enc,floc in zip(encodeharq,facelocq):\n",
    "    \n",
    "        results=face_recognition.compare_faces(encodelistknown,enc)\n",
    "        dresults=face_recognition.face_distance(encodelistknown,enc)\n",
    "        print(dresults)\n",
    "        matchind=np.argmin(dresults)\n",
    "        if results[matchind]:\n",
    "            name=classnames[matchind]\n",
    "            print(name)\n",
    "            y1,x2,y2,x1=floc\n",
    "            y1,x2,y2,x1=y1*4,x2*4,y2*4,x1*4\n",
    "            cv2.rectangle(img,(floc[3],floc[0]),(floc[1],floc[2]),(0,255,0),2)\n",
    "            #cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
    "            cv2.putText(img,name,(25,25),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "            s=mycol.find_one({})\n",
    "            now=datetime.datetime.now()\n",
    "            dtstring=now.strftime('%H:%M:%S')\n",
    "            mydict = { \"name\": name, \"date\":dtstring}\n",
    "            mycol.insert_one(mydict)\n",
    "            cv2.imshow('frame',img)\n",
    "            c=c+1\n",
    "        if c==2:\n",
    "            flag=False\n",
    "# When everything done, release the capture \n",
    "cap.release() \n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 633, 705, 312)\n",
      "[0.57941281 0.88289557 0.26852943]\n",
      "SURIYA\n",
      "(44, 135, 95, 83)\n",
      "[False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Demo using sample Image \n",
    "\n",
    "img1=face_recognition.load_image_file('hs/suriya.jpeg')\n",
    "img1=cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)\n",
    "faceloc=face_recognition.face_locations(img1)[0]\n",
    "print(faceloc)\n",
    "encodehar=face_recognition.face_encodings(img1)[0]\n",
    "results=face_recognition.compare_faces(encodelistknown,encodehar)\n",
    "dresults=face_recognition.face_distance(encodelistknown,encodehar)\n",
    "#cv2.putText(img2,f'{results}{round(dresults[0],2)}',(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,255))\n",
    "print(dresults)\n",
    "matchind=np.argmin(dresults)\n",
    "if results[matchind]:\n",
    "    name=classnames[matchind].upper()\n",
    "    print(name)\n",
    "    cv2.rectangle(img1,(faceloc[3],faceloc[0]),(faceloc[1],faceloc[2]),(255,0,255),2)\n",
    "    cv2.putText(img1,f'{name}{round(dresults[0],2)}',(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,255))\n",
    "cv2.imshow('image',img1)\n",
    "cv2.waitKey(0)  \n",
    "cv2.rectangle(img1,(faceloc[3],faceloc[0]),(faceloc[1],faceloc[2]),(255,0,255),2)\n",
    "img2=face_recognition.load_image_file('hs/himg.jpg')\n",
    "img2=cv2.cvtColor(img2,cv2.COLOR_BGR2RGB)\n",
    "faceloc1=face_recognition.face_locations(img2)[0]\n",
    "print(faceloc1)\n",
    "encodehar1=face_recognition.face_encodings(img2)[0]\n",
    "cv2.rectangle(img2,(faceloc1[3],faceloc1[0]),(faceloc1[1],faceloc1[2]),(255,0,255),2)\n",
    "#cv2.imshow('image',img1)\n",
    "#cv2.imshow('image',img2)\n",
    "results=face_recognition.compare_faces([encodehar],encodehar1)\n",
    "dresults=face_recognition.face_distance([encodehar],encodehar1)\n",
    "cv2.putText(img2,f'{results}{round(dresults[0],2)}',(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,255))\n",
    "print(results)\n",
    "cv2.imshow('image',img2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('60902e2cdcfce39041e5a65e'), 'name': 'suriya', 'date': '22:39:00'}\n",
      "{'_id': ObjectId('60902e2ddcfce39041e5a65f'), 'name': 'suriya', 'date': '22:39:01'}\n"
     ]
    }
   ],
   "source": [
    "#Displaying the Owners List detected from the database\n",
    "s=mycol.find({})\n",
    "for x in s:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
